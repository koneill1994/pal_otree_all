r3[1]
r3[length([3-1)]
r3[length(r3)-1]
r3[length(r3)]
r3[1:length(r3)]
r3[1:(length(r3)-1)]
words=paste(r3[1:(length(r3)-1)])
words
words=paste(r3[1:(length(r3)-1)],collapse = '')
words
wordlist=data.frame()
for(r in 1:nrow(ratpal)){
row=ratpal[r,]
r2=unlist(strsplit(as.character(row)," "))
r3=(r2[1:(length(r2)-10)])
match=r3[length(r3)]
words=paste(r3[1:(length(r3)-1)],collapse = '')
wordlist=rbind(wordlist,list(words,match))
}
wordlist
for(r in 1:nrow(ratpal)){
row=ratpal[r,]
r2=unlist(strsplit(as.character(row)," "))
r3=(r2[1:(length(r2)-10)])
match=r3[length(r3)]
words=paste(r3[1:(length(r3)-1)],collapse = '')
wordlist=rbind(wordlist,c(words,match))
}
wordlist
warnings()
wordlist=data.frame()
for(r in 1:nrow(ratpal)){
row=ratpal[r,]
r2=unlist(strsplit(as.character(row)," "))
r3=(r2[1:(length(r2)-10)])
match=r3[length(r3)]
words=paste(r3[1:(length(r3)-1)],collapse = '')
wordlist=rbind(wordlist,data.frame(words,match))
}
wordlist
write.csv(wordlist,"ratpal_words.csv")
getwd()
View(ratpal)
ratpal=read.csv(file.choose(),header=FALSE)
View(ratpal)
wordlist=data.frame()
for(r in 1:nrow(ratpal)){
row=ratpal[r,]
r2=unlist(strsplit(as.character(row)," "))
r3=(r2[1:(length(r2)-10)])
match=r3[length(r3)]
words=paste(r3[1:(length(r3)-1)],collapse = '')
wordlist=rbind(wordlist,data.frame(words,match))
}
write.csv(wordlist,"ratpal_words.csv")
wordlist
wordlist
write.csv(wordlist,"ratpal_words.csv")
json.dumps(wordlist)
library(jsonlite)
json.dumps(wordlist)
toJSON(wordlist)
list(wordlist)
wordpairs=list()
for(r in 1:nrow(ratpal)){
row=ratpal[r,]
r2=unlist(strsplit(as.character(row)," "))
r3=(r2[1:(length(r2)-10)])
match=r3[length(r3)]
words=paste(r3[1:(length(r3)-1)],collapse = '')
wordlist=rbind(wordlist,data.frame(words,match))
wordpairs.append(list(words,match))
}
wordpairs=vector("list",nrows(ratpal))
wordpairs=vector("list",nrow(ratpal))
wordpairs=vector("list",nrow(ratpal))
for(r in 1:nrow(ratpal)){
row=ratpal[r,]
r2=unlist(strsplit(as.character(row)," "))
r3=(r2[1:(length(r2)-10)])
match=r3[length(r3)]
words=paste(r3[1:(length(r3)-1)],collapse = '')
wordlist=rbind(wordlist,data.frame(words,match))
wordpairs[.append][r]]=(list(words,match))
}
wordpairs[[r]]=(list(words,match))
wordpairs=vector("list",nrow(ratpal))
for(r in 1:nrow(ratpal)){
row=ratpal[r,]
r2=unlist(strsplit(as.character(row)," "))
r3=(r2[1:(length(r2)-10)])
match=r3[length(r3)]
words=paste(r3[1:(length(r3)-1)],collapse = '')
wordlist=rbind(wordlist,data.frame(words,match))
wordpairs[[r]]=(list(words,match))
}
wordpairs
toJSON(wordpairs)
write(toJSON(wordpairs),"wordlist.json")
library(jsonlite)
ratpal=read.csv(file.choose(),header=FALSE)
View(ratpal)
wordlist=data.frame()
wordpairs=vector("list",nrow(ratpal))
r
r=1
row=ratpal[r,]
row
r2=unlist(strsplit(as.character(row)," "))
r2
r3=(r2[1:(length(r2)-10)])
r3
r3[length(r3)]
match=r3[length(r3)]
r3[1:(length(r3)-1)]
paste(r3[1:(length(r3)-1)],collapse = '')
words=paste(r3[1:(length(r3)-1)],collapse = '')
data.frame(words,match)
for(r in 1:nrow(ratpal)){
row=ratpal[r,]
r2=unlist(strsplit(as.character(row)," "))
r3=(r2[1:(length(r2)-10)])
match=r3[length(r3)]
words=paste(r3[1:(length(r3)-1)],collapse = '')
wordlist=rbind(wordlist,data.frame(words,match))
wordpairs[[r]]=(list(words,match))
}
View(wordlist)
for(r in 1:nrow(ratpal)){
row=ratpal[r,]
r2=unlist(strsplit(as.character(row)," "))
r3=(r2[1:(length(r2)-10)])
match=r3[length(r3)]
words=paste(r3[1:(length(r3)-1)],collapse = '')
wordlist=rbind(wordlist,data.frame(words,match))
wordpairs[[r]]=(list(words,match))
}
wordpairs
toJSON(wordpairs)
df1=read.csv("D:/downloads_D/CR.Motivation Survey Items.csv")
View(df1)
df1=read.csv("D:/downloads_D/CR.Motivation Survey Items.csv",header=F)
View(df1)
df1[,1]
any(df1[,1])
any(df1[,10])
any(df1[,1])
df1=read.csv("D:/downloads_D/CR.Motivation Survey Items.csv",header=F,stringsAsFactors = F)
any(df1[,1])
any(is.character(df1[,1]))
all(is.character(df1[,1]))
(is.character(df1[,1]))
(is.character(df1[,1]))
(is.character(df1[,10]))
any(is.character(df1[,10]))
apply(df1,2,function(x){
df1[,any(is.character(x))]
})
Filter(function(x)!all(is.na(x)), df1)
View(Filter(function(x)!all(is.na(x)), df1))
df1=(Filter(function(x)!all(is.na(x)), df1))
pages=df1[,1]
pages=df1[,1]
p=""
for(r in length(pages){
for(r in length(pages)){
if(pages[r]!=""){
p=pages[r]
}
else{
pages[r]=p
}
}
pages
for(r in length(pages)){
if(pages[r]!=""){
p=pages[r]
}
else{
pages[r]=p
}
}
pages[r]
pages[r]!=""
p
r
for(r in 1:length(pages)){
if(pages[r]!=""){
p=pages[r]
}
else{
pages[r]=p
}
}
df1[,1]=pages
df1[,1]=pages
colnames(df1)=c("page","survey","text")
# careless responding script
# first load in the data
df1=read.csv("D:/downloads_D/CR.Motivation Survey Items.csv",header=F,stringsAsFactors = F)
df1=(Filter(function(x)!all(is.na(x)), df1))
# correct for blank entries
pages=df1[,1]
p=""
for(r in 1:length(pages)){
if(pages[r]!=""){
p=pages[r]
}
else{
pages[r]=p
}
}
df1[,1]=pages
colnames(df1)=c("page","survey","text")
df1$page=unlist(
lapply(df1$page,
function(x){
ifelse(x=="page 13",
"Page 13",
x)
}
)
)
item_scale_list=list(
GO="GoalOrientation",
"F"="GoalOrientation",
O="Big5",
C="Big5",
E="Big5",
A="Big5",
N="Big5",
IM="Likert7",
WE="Likert5",
d="Likert5",
m="Likert5",
Infreq="Likert5",
Syn="Likert5",
Ant="Likert5",
RI="Likert5",
RIR="Likert5",
Dem="Likert5",
Age="StringInput",
Gender="StringInput"
)
scales=
lapply(df1$survey,function(x){
item_scale_list[unlist(strsplit(x,"_"))[1]]
}
)
df1$scale=unlist(scales)
# in case we want to look at which items are semantic synonyms or antonyms etc
if(F){
View(df1[sapply(strsplit(df1$survey,"_"),function(x){x[1]})=="Ant",])
View(df1[sapply(strsplit(df1$survey,"_"),function(x){x[1]})=="Syn",])
View(df1[sapply(strsplit(df1$survey,"_"),function(x){x[1]})=="Infreq",])
View(df1[sapply(strsplit(df1$survey,"_"),function(x){x[1]})=="RIR",])
}
## setting answers to infrequency items
infreq_items=c(
"I can teleport across time and space.",
"I have never used a computer.",
"I enjoy receiving telemarketer's calls."	,
"I have been to every country in the world.",
"I sleep less than one hour per night.",
"I have never brushed my teeth.",
"I don’t like getting speeding tickets.",
"It feels good to be appreciated.",
"I’d be happy if I won the lottery.",
"I look forward to my time off.",
"I am using an electronic device currently.",
"I have felt tired or sleepy in my lifetime."
)
items_ans=c(rep(1,6),rep(5,6))
q_ordered=df1[sapply(strsplit(df1$survey,"_"),function(x){x[1]})=="Infreq",]$text
infreq_answers=items_ans[apply(adist(infreq_items,q_ordered),2,which.min)]
# setting response options to RIR items
rir_survey=df1[sapply(strsplit(df1$survey,"_"),function(x){x[1]})=="RIR",]$survey
setwd("D:/otree/oTree/cr_survey")
fileConn<-file("RIR_items")
rir_items=readLines(fileConn)
close(fileConn)
rir_resps=c()
for(i in which(substr(rir_items,0,1)=="Q")){
resp=c()
for(item in rir_items[i+1:4]){
resp=c(resp,unlist(strsplit(unlist(strsplit(item,"\t"))[2],"  "))[1])
}
rir_resps=c(rir_resps,resp)
}
# rir_resps is the responses for each each rir item in order
# grab each set individually with this
# rir_resp_l=lapply(1:(length(rir_resps)/4),function(x){rir_resps[(x-1)*4+1:4]})
make_mls_func=function(pagelist){
prepend="
def checkMaxLongString(self):
s=0
c=0"
append="
return self.div_z(s,c)"
body="
(s,c)=self.IterateMLS(%s,s,c)"
middle=c()
for(page in pagelist){
p_name=paste0(unlist(strsplit(page," ")),collapse="_")
middle=c(middle,sprintf(body,paste0("self.",p_name,"_MLS"),collapse=""))
}
return(paste0(prepend,paste0(middle,collapse=""),append,collapse=""))
}
make_syn_func=function(){
prepend="
def checkSynonym(self):
s=0
c=0"
append="
return self.div_z(s,c)"
body="
(s,c)=self.IterateSyn(%s,%s,s,c)"
syn=df1[sapply(strsplit(df1$survey,"_"),function(x){x[1]})=="Syn",]$survey
syn_list=unlist(lapply(syn,function(x){substr(x,1,nchar(x)-1)}))
middle=c()
for(sn in syn_list){
middle=c(middle,sprintf(body,paste0("self.",sn,"a"),paste0("self.",sn,"b")))
}
return(paste0(prepend,paste0(middle,collapse=""),append,collapse=""))
}
make_ant_func=function(){
prepend="
def checkAntonym(self):
s=0
c=0"
append="
return self.div_z(s,c)"
body="
(s,c)=self.IterateAnt(%s,%s,s,c)"
ant=df1[sapply(strsplit(df1$survey,"_"),function(x){x[1]})=="Ant",]$survey
ant_list=unlist(lapply(ant,function(x){substr(x,1,nchar(x)-1)}))
middle=c()
for(an in ant_list){
middle=c(middle,sprintf(body,paste0("self.",an,"a"),paste0("self.",an,"b")))
}
return(paste0(prepend,paste0(middle,collapse=""),append,collapse=""))
}
make_infreq_func=function(){
prepend="
def checkInfreq(self):
s=0
c=0"
append="
return self.div_z(s,c)"
body="
(s,c)=self.IterateInfreq(self.%s,%s,s,c)"
infreq_l=df1[sapply(strsplit(df1$survey,"_"),function(x){x[1]})=="Infreq",]$survey
middle=c()
for(n in 1:length(infreq_l)){
middle=c(middle,sprintf(body,infreq_l[n],paste0("Constants.infreq_ans[",as.character(n-1),"]")))
}
return(paste0(prepend,paste0(middle,collapse=""),append,collapse=""))
}
# def checkPageTime():
#   s=0
# c=0
# (s,c)=IteratePageTime(Page_1_Pagetime,len(Constants.Page_1),s,c)
# # calculated as 2*number of questions is the cutoff where more than this time indicates “good quality” and less time is careless.
# return s/c
make_pt_func=function(pagelist){
prepend="
def checkPageTime(self):
s=0
c=0"
append="
return self.div_z(s,c)"
body="
(s,c)=self.IteratePageTime(%s,%s,s,c)"
middle=c()
for(page in pagelist){
p_name=paste0(unlist(strsplit(page," ")),collapse="_")
middle=c(middle,sprintf(body,paste0("self.",p_name,"_Pagetime"),paste0("len(Constants.",p_name,")")))
}
return(paste0(prepend,paste0(middle,collapse=""),append,collapse=""))
}
{
# the variables which will bring our metrics from js into python
cr_measures=c("MLS","Infreq","Syn","Ant","Pagetime")
cr_measures_page=c("MLS","Pagetime")
# creating the code to paste into the otree models.py script
lines=c()
lines=c(lines,"# Paste the following into Constants")
# this bit will go in constants
lines=c(lines,paste0("infreq_ans=[",paste0(as.character(infreq_answers),collapse=","),"]"))
for(page in unique(df1$page)){
varname=paste0(unlist(strsplit(page," ")),collapse="_")
cr_page=sapply(cr_measures_page,function(x){paste0(varname,"_",x,collapse="")})
varlist=paste0(sapply(c(df1[df1$page == page,]$survey,cr_page),
function(x){paste0("\"",x,"\"",sep="")}),collapse=", ")
lines=c(lines,paste0(varname,"=[",varlist,"]"))
}
# separate them
lines=c(lines,"")
# this bit will go into player
lines=c(lines,"# Paste the following into player")
for(n in 1:nrow(df1)){
if(n %in% as.numeric(rownames(df1[lapply(strsplit(df1$survey,"_"),function(x){x[1]})!="RIR",]))){
row=df1[n,]
fix_rowtext=paste0(unlist(strsplit(row$text,"\"")),collapse="\\\"")
coderow=paste0(row$survey,"=",row$scale,"(\"",fix_rowtext,"\")")
fix_apos=paste0(unlist(strsplit(coderow,"’")),collapse="'")
lines=c(lines,fix_apos)
}
}
for(page in unique(df1$page)){
varname=paste0(unlist(strsplit(page," ")),collapse="_")
cr_page=sapply(cr_measures_page,function(x){paste0(varname,"_",x,collapse="")})
for(var in cr_page){
coderow=paste0(var,"=","StringInput","(\"",var,"\")")
lines=c(lines,coderow)
}
lines=c(lines,paste0(varname,"_cr=models.FloatField()"))
}
for(n in 1:length(rir_resp_l)){
choice_arr=paste0("[",paste0(paste0("\"",rir_resp_l[[n]],"\""),collapse=", "),"]")
rir_q=df1[sapply(strsplit(df1$survey,"_"),function(x){x[1]})=="RIR",]$text
fix_rowtext=paste0(unlist(strsplit(rir_q[n],"\"")),collapse="\\\"")
coderow=paste0(rir_survey[n],"=RIR_items(",paste0("\"",fix_rowtext,"\""),",",choice_arr,")")
lines=c(lines,coderow)
}
# functions to calculate all the submeasures
lines=c(lines,make_mls_func(unique(df1$page)))
lines=c(lines,make_pt_func(unique(df1$page)))
lines=c(lines,make_syn_func())
lines=c(lines,make_ant_func())
lines=c(lines,make_infreq_func())
lines=c(lines,"")
lines=c(lines,"# Paste the following into pages.py")
pc1=
"class Page_%s(Page):
form_model='player'
form_fields=Constants.Page_%s
def vars_for_template(self):
return(dict(
qnames=Constants.Page_%s"
page_class_cr=",
cr_score=self.player.Page_%s_cr"
page_class_cr2=",
cr_score=None"
pc2="
))
def before_next_page(self):
self.player.Page_%s_cr=self.player.get_CR_Metric()
"
for(n in 1:length(unique(df1$page))){
num=as.character(n)
part1=sprintf(pc1,num,num,num)
part_m=sprintf(page_class_cr,as.character(n-1))
part2=sprintf(pc2,num)
if(n==1){
part_m=page_class_cr2
}
lines=c(lines,paste0(part1,part_m,part2))
}
lines=c(lines,"")
lines=c(lines,"page_sequence = [")
for(page in unique(df1$page)){
p=paste0(unlist(strsplit(page," ")),collapse="_")
lines=c(lines,paste0("    ",p,",",sep=""))
}
lines=c(lines,"]")
# save it to a document
setwd("D:/downloads_D")
fileConn<-file("cr_for_otree.txt")
writeLines(lines,fileConn)
close(fileConn)
}
infreq_items
q_ordered
adist(infreq_items,q_ordered)
apply(adist(infreq_items,q_ordered),2,which.min)
items_ans[apply(adist(infreq_items,q_ordered),2,which.min)]
items_ans
1:100
x%%3
fb=function(x){
out=""
if(x%%3==0){
out=c(out,"fizz")
}
if(x%%5==0){
out=c(out,"buzz")
}
if(out==""){
return(as.character(x))
}
else{
return(out)
}
}
sapply(1:100,fb)
fb=function(x){
out=""
if(x%%3==0){
out=paste0(out,"fizz")
}
if(x%%5==0){
out=paste0(out,"buzz")
}
if(out==""){
return(as.character(x))
}
else{
return(out)
}
}
sapply(1:100,fb)
